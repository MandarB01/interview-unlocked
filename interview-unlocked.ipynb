{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd836ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -qU langchain langgraph langgraph-swarm langchain-google-genai google-generativeai langchain_community faiss-cpu tavily-python google-cloud-speech sounddevice scipy pdfminer.six python-dotenv langchain-openai numpy pandas pytesseract openpyxl langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0259e",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Install necessary libraries and import required modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262ab74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "#%pip install -qU langchain langgraph langgraph-swarm langchain-google-genai langchain_community faiss-cpu tavily-python google-cloud-speech sounddevice scipy pdfminer.six python-dotenv langchain-openai\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "import pytesseract\n",
    "\n",
    "# Replace Ollama with Google Generative AI (Gemini)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "# from langchain_ollama import ChatOllama # Removed unused import\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# Use pydantic.v1 for compatibility as suggested by the warning\n",
    "from pydantic.v1 import BaseModel, Field \n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "# Removed unused langgraph_swarm imports\n",
    "\n",
    "from google.cloud import speech\n",
    "from pdfminer.high_level import extract_text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API keys like Tavily, Google Cloud)\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "FAISS_RESUME_PATH = \"./faiss/resume_embeddings\"\n",
    "FAISS_JD_PATH = \"./faiss/jd_embeddings\"\n",
    "FAISS_RUBRIC_PATH = \"./faiss/rubric_embeddings\"\n",
    "FAISS_KNOWLEDGE_PATH = \"./faiss/knowledge_embeddings\"\n",
    "os.makedirs(os.path.dirname(FAISS_RESUME_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(FAISS_JD_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(FAISS_RUBRIC_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(FAISS_KNOWLEDGE_PATH), exist_ok=True)\n",
    "# Retrieve the API key loaded by load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize LLM (using Gemini)\n",
    "# Pass the API key explicitly\n",
    "# import google.generativeai as genai\n",
    "# genai.configure(api_key=google_api_key)\n",
    "# models = genai.list_models()\n",
    "\n",
    "# for m in models:\n",
    "#     print(m.name, m.supported_generation_methods)\n",
    "\n",
    "gemini_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",  # Must be valid in your project\n",
    "    temperature=0.1,\n",
    "    convert_system_message_to_human=True,\n",
    "    google_api_key=google_api_key  # from .env\n",
    ")\n",
    "\n",
    "# gemini_model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "# llm = ChatOllama(model=\"llama3\", temperature=0.1)\n",
    "\n",
    "# Initialize Embeddings Model (using Gemini)\n",
    "# Pass the API key explicitly\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "# embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Initialize Checkpointer\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3adb8",
   "metadata": {},
   "source": [
    "Okay, I will update the interview-unlocked.ipynb notebook to implement the agentic workflow described in design.md using `langgraph` and `langgraph_swarm`.\n",
    "\n",
    "Made changes.\n",
    "\n",
    "OK. I have populated the interview-unlocked.ipynb notebook with the Python code to implement the multi-agent interview preparation system based on your design.md file and using LangGraph.\n",
    "\n",
    "The notebook now contains the following sections:\n",
    "\n",
    "1.  **Setup and Imports:** Installs necessary packages (commented out by default) and imports all required libraries and modules. It also sets up configurations like FAISS paths and initializes the LLM and embedding models.\n",
    "2.  **Tool Definitions:** Implements all the tools required by the agents, such as text extraction, embedding generation, vector retrieval, web search, LeetCode retrieval (placeholder), audio recording/transcription, and evaluation helper tools (placeholders).\n",
    "3.  **Agent Definitions:** Defines the `InterviewState` TypedDict to manage the data flow between agents. It includes the prompts for each agent (Preprocessing, Knowledge, Planner, Question, Evaluation) derived from design.md and sets up the agent nodes using LangGraph's `ToolNode` and a helper function.\n",
    "4.  **Graph Definition:** Constructs the `StateGraph`, adds nodes for each agent and its tools, defines the sequential edges connecting them (Preprocessing -> Knowledge -> Planner -> Question -> Record Answer -> Evaluate -> END), and compiles the graph. It also includes code to optionally visualize the graph structure.\n",
    "5.  **Execution and Interaction:** Provides an example of how to run the graph. You'll need to **modify the `resume_file` and `jd_file` variables** to point to your actual resume and job description files. It then runs the graph asynchronously, streams the events (like tool calls and LLM outputs), and finally prints the key outputs extracted from the final state (study plan, suggested LeetCode, generated question, transcribed answer, and evaluation feedback).\n",
    "\n",
    "Please review the notebook, especially the placeholder file paths in the \"Execution and Interaction\" section, and ensure your environment (API keys, Ollama server if used, Google Cloud credentials) is set up correctly before running the cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2dadb",
   "metadata": {},
   "source": [
    "# Interview Unlocked: Agentic Interview Preparation System\n",
    "\n",
    "This notebook implements a multi-agent system using LangGraph and LangGraph Swarm to help users prepare for job interviews. It follows the design outlined in `design.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tool Implementations ---\n",
    "\n",
    "@tool\n",
    "def extract_text_with_ocr(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a file. Uses pdfminer.six for text-based PDF files,\n",
    "    pytesseract OCR for image-based PDFs (if Tesseract is installed),\n",
    "    otherwise reads as plain text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.lower().endswith('.pdf'):\n",
    "            print(f\"Extracting text from PDF: {file_path}\")\n",
    "            try:\n",
    "                # Use pdfminer.six for direct text extraction\n",
    "                text = extract_text(file_path)\n",
    "                print(\"PDF text extraction with pdfminer.six finished.\")\n",
    "                return text.strip()\n",
    "            except Exception as e_pdfminer:\n",
    "                print(f\"pdfminer.six failed: {e_pdfminer}. Falling back to OCR if possible.\")\n",
    "                # Fallback to OCR if pdfminer fails (optional, requires Tesseract)\n",
    "                try:\n",
    "                    pytesseract.get_tesseract_version() # Check if Tesseract is available\n",
    "                    # If you still want OCR as a fallback, you'd need pdf2image back.\n",
    "                    # For now, we just report the pdfminer error if OCR isn't the primary path.\n",
    "                    # If you re-introduce pdf2image for fallback:\n",
    "                    # from pdf2image import convert_from_path\n",
    "                    # images = convert_from_path(file_path)\n",
    "                    # full_text = \"\"\n",
    "                    # for i, image in enumerate(images):\n",
    "                    #     print(f\"Processing page {i+1}/{len(images)} via OCR fallback...\")\n",
    "                    #     ocr_text = pytesseract.image_to_string(image)\n",
    "                    #     full_text += ocr_text + \"\\n\"\n",
    "                    # print(\"PDF OCR fallback finished.\")\n",
    "                    # return full_text.strip()\n",
    "                    return f\"Error extracting text with pdfminer.six: {e_pdfminer}. OCR fallback not fully implemented without pdf2image.\"\n",
    "\n",
    "                except Exception as e_ocr_check:\n",
    "                     return f\"Error extracting text with pdfminer.six: {e_pdfminer}. Tesseract for OCR fallback not found: {e_ocr_check}\"\n",
    "        else:\n",
    "            # Handle non-PDF files as plain text\n",
    "            print(f\"Reading text file: {file_path}\")\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred while processing {file_path}: {e}\"\n",
    "\n",
    "@tool\n",
    "def generate_resume_embeddings_and_save(text: str) -> str:\n",
    "    \"\"\"Generates embeddings for the Job Description text and saves/updates the FAISS Resume index.\"\"\"\n",
    "    index_path = FAISS_RESUME_PATH # Use the specific path\n",
    "    try:\n",
    "        texts = [text] # FAISS expects a list\n",
    "        if os.path.exists(index_path):\n",
    "            vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            vectorstore.add_texts(texts)\n",
    "        else:\n",
    "            vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "        vectorstore.save_local(index_path)\n",
    "        return f\"Resume Embeddings generated and saved to {index_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating/saving Resume embeddings: {e}\"\n",
    "\n",
    "@tool\n",
    "def generate_jd_embeddings_and_save(text: str) -> str:\n",
    "    \"\"\"Generates embeddings for the Job Description text and saves/updates the FAISS JD index.\"\"\"\n",
    "    index_path = FAISS_JD_PATH # Use the specific path\n",
    "    try:\n",
    "        texts = [text] # FAISS expects a list\n",
    "        if os.path.exists(index_path):\n",
    "            vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            vectorstore.add_texts(texts)\n",
    "        else:\n",
    "            vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "        vectorstore.save_local(index_path)\n",
    "        return f\"JD Embeddings generated and saved to {index_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating/saving JD embeddings: {e}\"\n",
    "\n",
    "@tool\n",
    "def generate_knowledge_embeddings_and_save(text: str) -> str:\n",
    "    \"\"\"Generates embeddings for the Job Description text and saves/updates the FAISS Knowledge index.\"\"\"\n",
    "    index_path = FAISS_KNOWLEDGE_PATH # Use the specific path\n",
    "    try:\n",
    "        texts = [text] # FAISS expects a list\n",
    "        if os.path.exists(index_path):\n",
    "            vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            vectorstore.add_texts(texts)\n",
    "        else:\n",
    "            vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "        vectorstore.save_local(index_path)\n",
    "        return f\"Knowledge Embeddings generated and saved to {index_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating/saving Knowledge embeddings: {e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_rubric_embeddings_and_save(text: str) -> str:\n",
    "    \"\"\"Generates embeddings for the Job Description text and saves/updates the FAISS Rubric index.\"\"\"\n",
    "    index_path = FAISS_RUBRIC_PATH # Use the specific path\n",
    "    try:\n",
    "        texts = [text] # FAISS expects a list\n",
    "        if os.path.exists(index_path):\n",
    "            vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            vectorstore.add_texts(texts)\n",
    "        else:\n",
    "            vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "        vectorstore.save_local(index_path)\n",
    "        return f\"Rubric Embeddings generated and saved to {index_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating/saving Rubric embeddings: {e}\"\n",
    "\n",
    "@tool\n",
    "def retrieve_resume_embeddings_from_vector_db(query: str, k: int = 3) -> List[str]:\n",
    "    \"\"\"Retrieves relevant documents from the resume FAISS index.\"\"\"\n",
    "    try:\n",
    "        index_path = FAISS_RESUME_PATH\n",
    "        if not os.path.exists(index_path):\n",
    "            return [\"Resume vector index not found.\"]\n",
    "        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        return [doc.page_content for doc in results]\n",
    "    except Exception as e:\n",
    "        return [f\"Error retrieving from resume vector DB: {e}\"]\n",
    "    \n",
    "@tool\n",
    "def retrieve_jd_embeddings_from_vector_db(query: str, k: int = 3) -> List[str]:\n",
    "    \"\"\"Retrieves relevant documents from the JD FAISS index.\"\"\"\n",
    "    try:\n",
    "        index_path = FAISS_JD_PATH\n",
    "        if not os.path.exists(index_path):\n",
    "            return [\"JD vector index not found.\"]\n",
    "        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        return [doc.page_content for doc in results]\n",
    "    except Exception as e:\n",
    "        return [f\"Error retrieving from JD vector DB: {e}\"]\n",
    "\n",
    "@tool\n",
    "def retrieve_knowledge_embeddings_from_vector_db(query: str, k: int = 3) -> List[str]:\n",
    "    \"\"\"Retrieves relevant documents from the Knowledge FAISS index.\"\"\"\n",
    "    try:\n",
    "        index_path = FAISS_KNOWLEDGE_PATH\n",
    "        if not os.path.exists(index_path):\n",
    "            return [\"Knowledge vector index not found.\"]\n",
    "        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        return [doc.page_content for doc in results]\n",
    "    except Exception as e:\n",
    "        return [f\"Error retrieving from Knowledge vector DB: {e}\"]\n",
    "\n",
    "@tool\n",
    "def retrieve_rubric_embeddings_from_vector_db(query: str, k: int = 3) -> List[str]:\n",
    "    \"\"\"Retrieves relevant documents from the Rubric FAISS index.\"\"\"\n",
    "    try:\n",
    "        index_path = FAISS_RUBRIC_PATH\n",
    "        if not os.path.exists(index_path):\n",
    "            return [\"Rubric vector index not found.\"]\n",
    "        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        return [doc.page_content for doc in results]\n",
    "    except Exception as e:\n",
    "        return [f\"Error retrieving from Rubric vector DB: {e}\"]\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key from environment variables\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Check if the API key was loaded\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in environment variables. Please ensure it is set in your .env file.\")\n",
    "\n",
    "# Tavily Search Tool (already integrated in LangChain)\n",
    "# Pass the API key during initialization\n",
    "tavily_tool = TavilySearchResults(\n",
    "    tavily_api_key=tavily_api_key,\n",
    "    max_results=10\n",
    ")\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def web_retrieval_tavily_search() -> str:\n",
    "#     \"\"\"Used for searching the web for relevant discussion threads about the company\"\"\"\n",
    "#     # Load environment variables from .env file\n",
    "#     load_dotenv()\n",
    "\n",
    "#     # Retrieve the API key from environment variables\n",
    "#     tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "#     # Check if the API key was loaded\n",
    "#     if not tavily_api_key:\n",
    "#         raise ValueError(\"TAVILY_API_KEY not found in environment variables. Please ensure it is set in your .env file.\")\n",
    "\n",
    "#     # Tavily Search Tool (already integrated in LangChain)\n",
    "#     # Pass the API key during initialization\n",
    "#     tavily_tool = TavilySearchResults(\n",
    "#         tavily_api_key=tavily_api_key,\n",
    "#         max_results=20\n",
    "#     )\n",
    "\n",
    "#     print(tavily_tool)\n",
    "#     # results = tavily_tool.invoke(\"Amazon system design interview \")\n",
    "\n",
    "@tool\n",
    "def company_leetcode_problem_retriever(company: str, role_keywords: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieves suggested LeetCode questions for a specific company by reading\n",
    "    from the './Leetcode-company-problem-set.xlsx' file. Each company's\n",
    "    questions are expected to be in a sheet named after the company (case-insensitive).\n",
    "    Questions are assumed to be listed in the first column (A) starting from the first row (A1).\n",
    "    The role_keywords parameter is currently unused but available for future filtering.\n",
    "    \"\"\"\n",
    "    excel_path = './Leetcode-company-problem-set.xlsx'\n",
    "    default_questions = [\"Reverse Linked List\", \"Valid Parentheses\", \"Coin Change\"] # Default if company not found\n",
    "\n",
    "    print(f\"Fetching LeetCode questions for {company} from {excel_path}...\")\n",
    "\n",
    "    try:\n",
    "        # Check if file exists first\n",
    "        if not os.path.exists(excel_path):\n",
    "            print(f\"Error: Excel file not found at {excel_path}. Returning default questions.\")\n",
    "            return default_questions\n",
    "\n",
    "        # Read all sheet names first to handle case-insensitivity\n",
    "        xls = pd.ExcelFile(excel_path)\n",
    "        sheet_names = xls.sheet_names\n",
    "        target_sheet = None\n",
    "        for name in sheet_names:\n",
    "            if name.lower() == company.lower():\n",
    "                target_sheet = name\n",
    "                break\n",
    "\n",
    "        if target_sheet:\n",
    "            # Read the specific sheet, assuming no header and questions start at A1 (index 0)\n",
    "            df = pd.read_excel(excel_path, sheet_name=target_sheet, header=None)\n",
    "\n",
    "            if not df.empty and df.shape[1] > 0: # Check if dataframe is not empty and has at least one column\n",
    "                 # Questions are in the first column (index 0)\n",
    "                questions = df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "                if questions:\n",
    "                    print(f\"Found {len(questions)} questions for {company} in sheet '{target_sheet}'.\")\n",
    "                    return questions\n",
    "                else:\n",
    "                    print(f\"Sheet '{target_sheet}' for {company} found, but the first column is empty or contains only NaN values.\")\n",
    "                    return default_questions\n",
    "            else:\n",
    "                print(f\"Sheet '{target_sheet}' for {company} found but is empty or has no columns.\")\n",
    "                return default_questions\n",
    "        else:\n",
    "            print(f\"No specific sheet found for '{company}'. Returning default questions.\")\n",
    "            return default_questions\n",
    "\n",
    "    except FileNotFoundError: # Should be caught by os.path.exists, but kept for robustness\n",
    "        print(f\"Error: Excel file not found at {excel_path}. Returning default questions.\")\n",
    "        return default_questions\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the Excel file for {company}: {e}. Returning default questions.\")\n",
    "        return default_questions\n",
    "\n",
    "\n",
    "@tool\n",
    "def record_and_transcribe_audio(duration: int = 15, fs: int = 16000) -> str:\n",
    "    \"\"\"Records audio from the microphone for a specified duration and transcribes it using Google Cloud Speech-to-Text.\"\"\"\n",
    "    print(f\"Recording audio for {duration} seconds... Speak now!\")\n",
    "    audio_file = f\"/tmp/interview_answer_{uuid.uuid4()}.wav\"\n",
    "    try:\n",
    "        # Record audio\n",
    "        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "        # Convert to int16 and save\n",
    "        recording_int16 = np.int16(recording * 32767)\n",
    "        wav.write(audio_file, fs, recording_int16)\n",
    "        print(\"Audio recorded.\")\n",
    "\n",
    "        # Transcribe audio\n",
    "        print(\"Transcribing audio...\")\n",
    "        client = speech.SpeechClient() # Assumes GOOGLE_APPLICATION_CREDENTIALS is set\n",
    "        with open(audio_file, \"rb\") as f:\n",
    "            content = f.read()\n",
    "        audio = speech.RecognitionAudio(content=content)\n",
    "        config = speech.RecognitionConfig(\n",
    "            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz=fs,\n",
    "            language_code=\"en-US\",\n",
    "            enable_automatic_punctuation=True\n",
    "        )\n",
    "        response = client.recognize(config=config, audio=audio)\n",
    "        os.remove(audio_file) # Clean up temporary file\n",
    "\n",
    "        if not response.results:\n",
    "            print(\"Transcription failed: No speech detected.\")\n",
    "            return \"[No speech detected]\"\n",
    "\n",
    "        transcript = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
    "        print(f\"Transcription complete: {transcript}\")\n",
    "        return transcript.strip()\n",
    "    except Exception as e:\n",
    "        if os.path.exists(audio_file):\n",
    "            os.remove(audio_file)\n",
    "        error_msg = f\"Error during audio recording or transcription: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "\n",
    "# TODO Implement the below tools\n",
    "\n",
    "@tool\n",
    "def generate_ideal_answer(question: str, company_tag: Optional[str] = None) -> str:\n",
    "    \"\"\"Generates an ideal answer to the question (simulated by LLM call).\"\"\"\n",
    "    # This would typically involve another LLM call with specific instructions\n",
    "    # For simplicity here, we'll just return a placeholder or let the main agent handle it.\n",
    "    return f\"[Placeholder: Ideal answer generation for '{question}' considering company '{company_tag}']\"\n",
    "\n",
    "@tool\n",
    "def rewrite_candidate_answer(question: str, candidate_answer: str) -> str:\n",
    "    \"\"\"Rewrites the candidate's answer for improvement (simulated by LLM call).\"\"\"\n",
    "    return f\"[Placeholder: Rewritten version of answer for '{question}']\"\n",
    "\n",
    "@tool\n",
    "def critique_and_advise(question: str, candidate_answer: str, ideal_answer: str, company_tag: Optional[str] = None) -> str:\n",
    "    \"\"\"Provides critique and advice based on the answers (simulated by LLM call).\"\"\"\n",
    "    return f\"[Placeholder: Critique for answer to '{question}' considering company '{company_tag}']\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b67c2",
   "metadata": {},
   "source": [
    "## 3. Agent Definitions\n",
    "\n",
    "Define the state, prompts, and nodes for each agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd600388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF: ./Mandar_Burande_Resume.pdfReading text file: ./amazon-jd.txt\n",
      "\n",
      "PDF text extraction with pdfminer.six finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='The file path to my resume and jd is ./Mandar_Burande_Resume.pdf and ./amazon-jd.txt. Give me a study plan for cracking an interview with this company and also a list of popular leetcode problems for this company. Based on my experience, skills and projects from my resume, suggest me a question that will help me improve my skills for this company.', additional_kwargs={}, response_metadata={}, id='201cfc7f-6a56-409f-a662-36e287045e90'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'extract_text_with_ocr', 'arguments': '{\"file_path\": \"./amazon-jd.txt\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='preprocess_agent', id='run-ab9a70a2-a591-4964-a0da-8d7e3987efdc-0', tool_calls=[{'name': 'extract_text_with_ocr', 'args': {'file_path': './Mandar_Burande_Resume.pdf'}, 'id': '8e5a4c85-6543-490e-bfb2-2b177f7f7cef', 'type': 'tool_call'}, {'name': 'extract_text_with_ocr', 'args': {'file_path': './amazon-jd.txt'}, 'id': '813028e5-b7b5-449b-a897-a0a2808e2b6d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 509, 'output_tokens': 36, 'total_tokens': 545, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"MANDAR BURANDE \\n\\n mburande@asu.edu \\n\\n https://www.linkedin.com/in/mandar-burande/ \\n\\n https://mandarburande.me/ \\n\\nEducation \\n\\nArizona State University \\nMaster of Science, Computer Science \\n\\nAug 2024 - May 2026 \\n\\n• Coursework: Foundations of Algorithms, Computer Architecture II, Probabilistic Reasoning and Learning, Natural Language Processing, \\n\\nKnowledge Representation and Reasoning, Advanced Computer Network Security  \\n\\nNational Institute of Technology, Trichy \\nBachelor of Technology, Electrical and Electronics Engineering (GPA: 3.57 / 4) \\n\\nJul 2018 - May 2022 \\n\\n• Achievements: Graduated with a First Class with zero backlogs, Minors in Computer Science Engineering \\n• Coursework: Basics of Programming, Computer Organization, Data Structures and Algorithms, Database Management Systems, Big Data \\nAnalytics, Operating Systems, Microprocessors and Microcontrollers, Artificial Neural Networks, Data Communications and Networks, \\nCommunication Systems, Software Engineering  \\n\\nExperience \\n\\nASU Energy Efficiency Center | Database Developer \\n\\nDec 2024 - Present \\n\\n• Developed the full-stack official database website using React, Express.js, Node.js, and MongoDB, enhancing user accessibility and data \\n\\nmanagement  \\n\\n• Ensured the privacy and security of the database by aligning with the Department of Energy guidelines, reducing potential data breaches \\n• Consulted with industrial clients on cybersecurity measures and recommendations, leading to improved data protection and compliance \\nJul 2022 - Jul 2024  \\n• Collaborated with business users to revamp the FX Payment Tracker UI using Angular 14, enhancing user experience and aligning with \\n\\nWells Fargo | Software Engineer, Assistant Vice President \\n\\nthe latest technology standards  \\n\\n• Designed an event-streaming Notification service using Java, SpringBoot, and Apache Kafka, improving real-time data processing \\n\\ncapabilities. Transformed legacy business flows by transitioning from a monolithic to micro-services architecture, increasing system \\nscalability and flexibility  \\n\\n• Created an automated exception handling and retry mechanism to improve the performance of streaming and processing notifications from \\n\\n24 hours to 1 hour \\n\\n• Contributed to Wells Fargo being recognized as the Best FX Bank in North America in the Euromoney Foreign Exchange Awards 2023 \\n\\nby enhancing technology solutions in the Forex Payment Tracker team  \\n\\nCoffeeBeans Consulting LLP | Web Developer Intern \\n\\nJun 2021 - Aug 2021 \\n\\n• Developed REST APIs in Express.js and implemented backend data processing functions, enhancing data retrieval efficiency and system \\n\\nreliability  \\n\\n• Leveraged Data Visualization libraries such as Chart.js and D3.js to present processed data on the frontend, improving user engagement \\n\\nand data comprehension  \\n\\n• Improved the performance of the official website by 60% by reducing loading time, blocking time, and implementing asynchronous HTTP \\n\\nrequest processing  \\n\\nSkills \\n\\n• Programming Languages: Java, JavaScript, C++, Python, TypeScript \\n• Tools & Technologies: Git, Azure, AWS, Jenkins, Jupyter Notebook, GCP, Kubernetes, Node.js, Express.js, React.js, Angular, Spring- \\nBoot, MongoDB, SQL, Apache Kafka, Maven, Spring Data JPA, Java Messaging Service (JMS), IBM MQ, Redis, Mockito, Swagger, \\nPandas, Numpy, TensorFlow, PyTorch, UNIX, Agile, Jira, Docker  \\n\\n• Certifications: AZ-900: Microsoft Azure Fundamentals - Microsoft, Responsive Web Design - Coursera, University of London, Problem \\n\\nSolving - HackerRank  \\n\\nResearch and Project Work \\n\\nCyber Attack Detection In Power System SCADA Networks Using Machine Learning Techniques \\n\\nJan 2022 - May 2022 \\n\\n• Developed machine learning models to accurately identify cyber-attacks in increasingly connected supervisory control and data acquisition \\n(SCADA) networks. These models can be leveraged in power systems, power generation, and distribution plants to identify, thwart, and \\ncounter such malicious attacks.  \\n\\n• Utilized the Modbus Protocol to simulate communication between the Control Centre and the Field Devices. Simulated cyber attacks using \\n\\nthe Man-in-the-middle technique.  \\n\\n• Resulted in an accuracy of 96% in identifying malicious cyber-attacks. Wrote a thesis under the guidance of Dr. M Jaya Bharata Reddy.  \\n\\nWebsite Development for Currents '22 \\n\\nJun 2021 - Apr 2022 \\n• As the head of DevOps for the EEE Association, designed and developed the official website for EEE Department's annual symposium, \\n\\nCurrents 2022.  \\n\\n• Led a team of 12 department juniors and managed the workflows for front-end as well as backend development. Personally designed the \\n\\nbackend APIs to handle calls from both the web app and the Android app. \\n\\n• Used React.js for the frontend, Node.js for the backend, Express.js for REST APIs and MongoDB for database with Amazon AWS S3 for \\n\\nstorage. The backend served more than 10k API calls from the web and mobile apps over three days of the symposium\", name='extract_text_with_ocr', id='28532cf8-9cbd-4136-9c07-c0a9a3bb86dd', tool_call_id='8e5a4c85-6543-490e-bfb2-2b177f7f7cef'), ToolMessage(content=\"DESCRIPTION\\nIf you are interested in this position, please apply on Amazon's Career site https://www.Amazon.tv/jobs/en/\\n\\nAbout Us:\\n\\nAmazon is the world’s biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It is where thousands of communities come together for whatever, every day.\\nWe’re about community, inside and out. You’ll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We’re on a quest to empower live communities, so if this sounds good to you, see what we’re up to on LinkedIn and X,  and discover the projects we’re solving on our Blog. Be sure to explore our Interviewing Guide to learn how to ace our interview process.\\n\\nAbout the Role\\n\\nStreamer Monetization Experience is a team within the Commerce organization here at Amazon that focuses on ensuring our creators have the tools they need to make a living doing what they love. As an engineer here you'll help us continue to improve these experiences, like Emotes and Alerts, and build new features to help creators recognize and reward their supporters.\\n\\nAs an engineer on the team, you will work alongside a highly engaged and collaborative team that works to design, build and maintain systems that scale to millions of concurrent users. We actively seek to continue to improve our experiences for our users and are looking for new team members that share that passion for the end user.\\n\\nThis role is based out of our Seattle office.\\n\\nYou Will\\n\\n- Learn and contribute across the full stack of our software\\nBackend (Go), Web Frontend (React), Mobile Frontend (iOS / Android)\\n- Collaborate with fellow engineers, product managers and designers to build new products and solutions\\n- Participate in Operational Excellence work to maintain and support our live services\\n- Help earn customer trust by working with our support teams to resolve issues and fix production bugs\\n\\nPerks\\n- Medical, Dental, Vision & Disability Insurance\\n- 401(k)\\n- Maternity & Parental Leave\\n- Flexible PTO\\n- Amazon Employee Discount\\n\\nBASIC QUALIFICATIONS\\n- Willingness to learn new things and work with a diverse group of people\\n- A Bachelor's degree in Computer Science or equivalent industry experience as a Software Engineer\\n- A strong foundation in data structures and algorithms.\\n- Familiarity with scalability, concurrency, API design, data modeling, and distributed systems fundamentals.\\n- Proficiency in Go, Java, Python or another Object-oriented language\\n- An eagerness to grow as a Software Engineer\\n\\nPREFERRED QUALIFICATIONS\\n- Familiarity with AWS infrastructure\\n- Coding experience in either iOS or Android\\n- Coding experience with React\\n- Amazon experience / knowledge as a viewer, moderator or streamer\\n\\nWe are an equal opportunity employer and value diversity at Amazon. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.\\n\\nLos Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.\\n\\nOur compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $99,500/year in our lowest geographic market up to $200,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.\", name='extract_text_with_ocr', id='05eb420e-8e2a-4459-82ba-37c85c82a788', tool_call_id='813028e5-b7b5-449b-a897-a0a2808e2b6d'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'generate_jd_embeddings_and_save', 'arguments': '{\"text\": \"DESCRIPTION\\\\nIf you are interested in this position, please apply on Amazon\\'s Career site https://www.Amazon.tv/jobs/en/\\\\n\\\\nAbout Us:\\\\n\\\\nAmazon is the world\\\\u2019s biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It is where thousands of communities come together for whatever, every day.\\\\nWe\\\\u2019re about community, inside and out. You\\\\u2019ll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We\\\\u2019re on a quest to empower live communities, so if this sounds good to you, see what we\\\\u2019re up to on LinkedIn and X,  and discover the projects we\\\\u2019re solving on our Blog. Be sure to explore our Interviewing Guide to learn how to ace our interview process.\\\\n\\\\nAbout the Role\\\\n\\\\nStreamer Monetization Experience is a team within the Commerce organization here at Amazon that focuses on ensuring our creators have the tools they need to make a living doing what they love. As an engineer here you\\'ll help us continue to improve these experiences, like Emotes and Alerts, and build new features to help creators recognize and reward their supporters.\\\\n\\\\nAs an engineer on the team, you will work alongside a highly engaged and collaborative team that works to design, build and maintain systems that scale to millions of concurrent users. We actively seek to continue to improve our experiences for our users and are looking for new team members that share that passion for the end user.\\\\n\\\\nThis role is based out of our Seattle office.\\\\n\\\\nYou Will\\\\n\\\\n- Learn and contribute across the full stack of our software\\\\nBackend (Go), Web Frontend (React), Mobile Frontend (iOS / Android)\\\\n- Collaborate with fellow engineers, product managers and designers to build new products and solutions\\\\n- Participate in Operational Excellence work to maintain and support our live services\\\\n- Help earn customer trust by working with our support teams to resolve issues and fix production bugs\\\\n\\\\nPerks\\\\n- Medical, Dental, Vision & Disability Insurance\\\\n- 401(k)\\\\n- Maternity & Parental Leave\\\\n- Flexible PTO\\\\n- Amazon Employee Discount\\\\n\\\\nBASIC QUALIFICATIONS\\\\n- Willingness to learn new things and work with a diverse group of people\\\\n- A Bachelor\\'s degree in Computer Science or equivalent industry experience as a Software Engineer\\\\n- A strong foundation in data structures and algorithms.\\\\n- Familiarity with scalability, concurrency, API design, data modeling, and distributed systems fundamentals.\\\\n- Proficiency in Go, Java, Python or another Object-oriented language\\\\n- An eagerness to grow as a Software Engineer\\\\n\\\\nPREFERRED QUALIFICATIONS\\\\n- Familiarity with AWS infrastructure\\\\n- Coding experience in either iOS or Android\\\\n- Coding experience with React\\\\n- Amazon experience / knowledge as a viewer, moderator or streamer\\\\n\\\\nWe are an equal opportunity employer and value diversity at Amazon. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.\\\\n\\\\nLos Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company\\\\u2019s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\\\n\\\\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\\\n\\\\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you\\\\u2019re applying in isn\\\\u2019t listed, please contact your Recruiting Partner.\\\\n\\\\nOur compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $99,500/year in our lowest geographic market up to $200,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='preprocess_agent', id='run-14478aaf-be84-46c8-a4b9-b707cbb4182d-0', tool_calls=[{'name': 'generate_resume_embeddings_and_save', 'args': {'text': \"MANDAR BURANDE \\n\\n mburande@asu.edu \\n\\n https://www.linkedin.com/in/mandar-burande/ \\n\\n https://mandarburande.me/ \\n\\nEducation \\n\\nArizona State University \\nMaster of Science, Computer Science \\n\\nAug 2024 - May 2026 \\n\\n• Coursework: Foundations of Algorithms, Computer Architecture II, Probabilistic Reasoning and Learning, Natural Language Processing, \\n\\nKnowledge Representation and Reasoning, Advanced Computer Network Security  \\n\\nNational Institute of Technology, Trichy \\nBachelor of Technology, Electrical and Electronics Engineering (GPA: 3.57 / 4) \\n\\nJul 2018 - May 2022 \\n\\n• Achievements: Graduated with a First Class with zero backlogs, Minors in Computer Science Engineering \\n• Coursework: Basics of Programming, Computer Organization, Data Structures and Algorithms, Database Management Systems, Big Data \\nAnalytics, Operating Systems, Microprocessors and Microcontrollers, Artificial Neural Networks, Data Communications and Networks, \\nCommunication Systems, Software Engineering  \\n\\nExperience \\n\\nASU Energy Efficiency Center | Database Developer \\n\\nDec 2024 - Present \\n\\n• Developed the full-stack official database website using React, Express.js, Node.js, and MongoDB, enhancing user accessibility and data \\n\\nmanagement  \\n\\n• Ensured the privacy and security of the database by aligning with the Department of Energy guidelines, reducing potential data breaches \\n• Consulted with industrial clients on cybersecurity measures and recommendations, leading to improved data protection and compliance \\nJul 2022 - Jul 2024  \\n• Collaborated with business users to revamp the FX Payment Tracker UI using Angular 14, enhancing user experience and aligning with \\n\\nWells Fargo | Software Engineer, Assistant Vice President \\n\\nthe latest technology standards  \\n\\n• Designed an event-streaming Notification service using Java, SpringBoot, and Apache Kafka, improving real-time data processing \\n\\ncapabilities. Transformed legacy business flows by transitioning from a monolithic to micro-services architecture, increasing system \\nscalability and flexibility  \\n\\n• Created an automated exception handling and retry mechanism to improve the performance of streaming and processing notifications from \\n\\n24 hours to 1 hour \\n\\n• Contributed to Wells Fargo being recognized as the Best FX Bank in North America in the Euromoney Foreign Exchange Awards 2023 \\n\\nby enhancing technology solutions in the Forex Payment Tracker team  \\n\\nCoffeeBeans Consulting LLP | Web Developer Intern \\n\\nJun 2021 - Aug 2021 \\n\\n• Developed REST APIs in Express.js and implemented backend data processing functions, enhancing data retrieval efficiency and system \\n\\nreliability  \\n\\n• Leveraged Data Visualization libraries such as Chart.js and D3.js to present processed data on the frontend, improving user engagement \\n\\nand data comprehension  \\n\\n• Improved the performance of the official website by 60% by reducing loading time, blocking time, and implementing asynchronous HTTP \\n\\nrequest processing  \\n\\nSkills \\n\\n• Programming Languages: Java, JavaScript, C++, Python, TypeScript \\n• Tools & Technologies: Git, Azure, AWS, Jenkins, Jupyter Notebook, GCP, Kubernetes, Node.js, Express.js, React.js, Angular, Spring- \\nBoot, MongoDB, SQL, Apache Kafka, Maven, Spring Data JPA, Java Messaging Service (JMS), IBM MQ, Redis, Mockito, Swagger, \\nPandas, Numpy, TensorFlow, PyTorch, UNIX, Agile, Jira, Docker  \\n\\n• Certifications: AZ-900: Microsoft Azure Fundamentals - Microsoft, Responsive Web Design - Coursera, University of London, Problem \\n\\nSolving - HackerRank  \\n\\nResearch and Project Work \\n\\nCyber Attack Detection In Power System SCADA Networks Using Machine Learning Techniques \\n\\nJan 2022 - May 2022 \\n\\n• Developed machine learning models to accurately identify cyber-attacks in increasingly connected supervisory control and data acquisition \\n(SCADA) networks. These models can be leveraged in power systems, power generation, and distribution plants to identify, thwart, and \\ncounter such malicious attacks.  \\n\\n• Utilized the Modbus Protocol to simulate communication between the Control Centre and the Field Devices. Simulated cyber attacks using \\n\\nthe Man-in-the-middle technique.  \\n\\n• Resulted in an accuracy of 96% in identifying malicious cyber-attacks. Wrote a thesis under the guidance of Dr. M Jaya Bharata Reddy.  \\n\\nWebsite Development for Currents '22 \\n\\nJun 2021 - Apr 2022 \\n• As the head of DevOps for the EEE Association, designed and developed the official website for EEE Department's annual symposium, \\n\\nCurrents 2022.  \\n\\n• Led a team of 12 department juniors and managed the workflows for front-end as well as backend development. Personally designed the \\n\\nbackend APIs to handle calls from both the web app and the Android app. \\n\\n• Used React.js for the frontend, Node.js for the backend, Express.js for REST APIs and MongoDB for database with Amazon AWS S3 for \\n\\nstorage. The backend served more than 10k API calls from the web and mobile apps over three days of the symposium\"}, 'id': 'ce113152-b217-4e95-97c3-61bf782c1eab', 'type': 'tool_call'}, {'name': 'generate_jd_embeddings_and_save', 'args': {'text': \"DESCRIPTION\\nIf you are interested in this position, please apply on Amazon's Career site https://www.Amazon.tv/jobs/en/\\n\\nAbout Us:\\n\\nAmazon is the world’s biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It is where thousands of communities come together for whatever, every day.\\nWe’re about community, inside and out. You’ll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We’re on a quest to empower live communities, so if this sounds good to you, see what we’re up to on LinkedIn and X,  and discover the projects we’re solving on our Blog. Be sure to explore our Interviewing Guide to learn how to ace our interview process.\\n\\nAbout the Role\\n\\nStreamer Monetization Experience is a team within the Commerce organization here at Amazon that focuses on ensuring our creators have the tools they need to make a living doing what they love. As an engineer here you'll help us continue to improve these experiences, like Emotes and Alerts, and build new features to help creators recognize and reward their supporters.\\n\\nAs an engineer on the team, you will work alongside a highly engaged and collaborative team that works to design, build and maintain systems that scale to millions of concurrent users. We actively seek to continue to improve our experiences for our users and are looking for new team members that share that passion for the end user.\\n\\nThis role is based out of our Seattle office.\\n\\nYou Will\\n\\n- Learn and contribute across the full stack of our software\\nBackend (Go), Web Frontend (React), Mobile Frontend (iOS / Android)\\n- Collaborate with fellow engineers, product managers and designers to build new products and solutions\\n- Participate in Operational Excellence work to maintain and support our live services\\n- Help earn customer trust by working with our support teams to resolve issues and fix production bugs\\n\\nPerks\\n- Medical, Dental, Vision & Disability Insurance\\n- 401(k)\\n- Maternity & Parental Leave\\n- Flexible PTO\\n- Amazon Employee Discount\\n\\nBASIC QUALIFICATIONS\\n- Willingness to learn new things and work with a diverse group of people\\n- A Bachelor's degree in Computer Science or equivalent industry experience as a Software Engineer\\n- A strong foundation in data structures and algorithms.\\n- Familiarity with scalability, concurrency, API design, data modeling, and distributed systems fundamentals.\\n- Proficiency in Go, Java, Python or another Object-oriented language\\n- An eagerness to grow as a Software Engineer\\n\\nPREFERRED QUALIFICATIONS\\n- Familiarity with AWS infrastructure\\n- Coding experience in either iOS or Android\\n- Coding experience with React\\n- Amazon experience / knowledge as a viewer, moderator or streamer\\n\\nWe are an equal opportunity employer and value diversity at Amazon. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.\\n\\nLos Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.\\n\\nOur compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $99,500/year in our lowest geographic market up to $200,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.\"}, 'id': '737810b2-923f-4d9d-a3c7-e50ffa366ef8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2757, 'output_tokens': 2216, 'total_tokens': 4973, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"Error generating/saving Resume embeddings: Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open faiss/resume_embeddings/index.faiss for reading: No such file or directory\", name='generate_resume_embeddings_and_save', id='fb1328d1-ad8e-4ac5-a762-74a9fcfe3a2e', tool_call_id='ce113152-b217-4e95-97c3-61bf782c1eab'), ToolMessage(content=\"Error generating/saving JD embeddings: Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open faiss/jd_embeddings/index.faiss for reading: No such file or directory\", name='generate_jd_embeddings_and_save', id='fcfa7432-23b4-496d-9761-c95eea851190', tool_call_id='737810b2-923f-4d9d-a3c7-e50ffa366ef8'), AIMessage(content='I have extracted the text from the resume and job description, and attempted to generate and save the embeddings. However, I encountered an error when trying to save the embeddings to the FAISS index. The error message indicates that the specified file or directory does not exist. I will proceed by providing the company name and handoff to the knowledge agent.', additional_kwargs={'function_call': {'name': 'transfer_to_knowledge_agent', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='preprocess_agent', id='run-db45cd1c-9a00-43f1-86a4-bd869aa14537-0', tool_calls=[{'name': 'transfer_to_knowledge_agent', 'args': {}, 'id': '14daa986-18c5-4d0a-aa40-90f25f9a35f5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5163, 'output_tokens': 77, 'total_tokens': 5240, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to knowledge_agent', name='transfer_to_knowledge_agent', id='0f656348-d0c8-451a-8ac9-924569fa3af2', tool_call_id='14daa986-18c5-4d0a-aa40-90f25f9a35f5'), AIMessage(content='Okay, I will now perform my duties as the Knowledge Agent.', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"amazon software engineer interview communication site:glassdoor.com\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='knowledge_agent', id='run-5433f8fb-81f7-44a1-8af5-94fe3086e8a2-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'amazon coding interview expectations site:reddit.com'}, 'id': '0d01b163-2268-4cf0-aeb7-4a1ed421df07', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'amazon behavioral interview rubric site:glassdoor.com'}, 'id': '503fec8d-8a25-4e2b-9a7b-ae1b139d26be', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'amazon system design interview site:blind.com'}, 'id': 'aad8ea0c-07b5-4576-a77f-ab176af56e20', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'amazon software engineer interview communication site:glassdoor.com'}, 'id': '9533b5f4-7bef-4bd9-900c-7038ce9e1453', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5554, 'output_tokens': 89, 'total_tokens': 5643, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Help!! Amazon Technical Phone Interview in a week\", \"url\": \"https://www.reddit.com/r/leetcode/comments/wl2d5b/help_amazon_technical_phone_interview_in_a_week/\", \"content\": \"I have a technical phone interview with Amazon in 1 week. I am expected to code with an interviewer in 60 min session.\", \"score\": 0.5911811}, {\"title\": \"Amazon SDE 1 interview loop -- USA : r/leetcode\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1gajj96/amazon_sde_1_interview_loop_usa/\", \"content\": \"I felt pretty good about my answers, and the interviewer responded positively, saying \\\\\"good\\\\\" to most of them. After that, we moved on to the\", \"score\": 0.487918}, {\"title\": \"A detailed interview experience at Amazon - New grad (on- ...\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1gsvyt0/a_detailed_interview_experience_at_amazon_new/\", \"content\": \"This round would consist of two parts: the first half would focus on Leadership Principles (LP), and the second half would be a coding challenge.\", \"score\": 0.42176673}, {\"title\": \"My Amazon interview experience 2025 New Grad : r/leetcode\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1hx1swr/my_amazon_interview_experience_2025_new_grad/\", \"content\": \"The interviewer first asked me to go through my resume, asked some basic LP questions. Nothing fancy or out of the blue, and asked some follow up questions.\", \"score\": 0.39578846}, {\"title\": \"Amazon SDE 2 interview in 3 weeks. What should i focus on?\", \"url\": \"https://www.reddit.com/r/leetcode/comments/t94igs/amazon_sde_2_interview_in_3_weeks_what_should_i/\", \"content\": \"For system design I found grokking to be the best, for coding it is useful to pay for premium and focus on Amazon questions. As others said LP\", \"score\": 0.31913248}, {\"title\": \"Preparing for Amazon SDE Interview – Looking for Prep Tips\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1g9pujj/preparing_for_amazon_sde_interview_looking_for/\", \"content\": \"Commonly asked technical questions (especially around algorithms and data structures). · Example behavioral questions and what to expect\", \"score\": 0.25902867}, {\"title\": \"How to Prepare for Amazon SDE Interview - New Grad 2024?\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1g942ao/how_to_prepare_for_amazon_sde_interview_new_grad/\", \"content\": \"What kind of coding questions should I focus on? (Any specific patterns/types?) Generally, the questions are easy/medium, the types vary from\", \"score\": 0.21905375}, {\"title\": \"Amazon Final Interview Questions | All Combined 2021\", \"url\": \"https://www.reddit.com/r/leetcode/comments/qz2atz/amazon_final_interview_questions_all_combined/\", \"content\": \"Fourth round: 2-3 behavioral questions. This was another coding round, which involved taking a string that say said \\\\\"This sweater cost $40\", \"score\": 0.2040566}, {\"title\": \"I have an hour interview with live coding and LP ...\", \"url\": \"https://www.reddit.com/r/leetcode/comments/tgxaai/i_have_an_hour_interview_with_live_coding_and_lp/\", \"content\": \"Do Amazon tagged top 30 questions or so sorted based on frequency. Do these questions thoroughly, like understand what\\'s the optimal answer and such.\", \"score\": 0.17694198}, {\"title\": \"A detailed guide on How I prepared for an interview ...\", \"url\": \"https://www.reddit.com/r/leetcode/comments/1h5d3bc/a_detailed_guide_on_how_i_prepared_for_an/\", \"content\": \"Onsite interviews typically involve 30–40 minutes of solving problems, dry runs, follow-ups, and managing pressure.\", \"score\": 0.06261143}]', name='tavily_search_results_json', id='eb73c3d7-fcb4-4935-b4ea-6947db0a400b', tool_call_id='0d01b163-2268-4cf0-aeb7-4a1ed421df07', artifact={'query': 'amazon coding interview expectations site:reddit.com', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.reddit.com/r/leetcode/comments/wl2d5b/help_amazon_technical_phone_interview_in_a_week/', 'title': 'Help!! Amazon Technical Phone Interview in a week', 'content': 'I have a technical phone interview with Amazon in 1 week. I am expected to code with an interviewer in 60 min session.', 'score': 0.5911811, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1gajj96/amazon_sde_1_interview_loop_usa/', 'title': 'Amazon SDE 1 interview loop -- USA : r/leetcode', 'content': 'I felt pretty good about my answers, and the interviewer responded positively, saying \"good\" to most of them. After that, we moved on to the', 'score': 0.487918, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1gsvyt0/a_detailed_interview_experience_at_amazon_new/', 'title': 'A detailed interview experience at Amazon - New grad (on- ...', 'content': 'This round would consist of two parts: the first half would focus on Leadership Principles (LP), and the second half would be a coding challenge.', 'score': 0.42176673, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1hx1swr/my_amazon_interview_experience_2025_new_grad/', 'title': 'My Amazon interview experience 2025 New Grad : r/leetcode', 'content': 'The interviewer first asked me to go through my resume, asked some basic LP questions. Nothing fancy or out of the blue, and asked some follow up questions.', 'score': 0.39578846, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/t94igs/amazon_sde_2_interview_in_3_weeks_what_should_i/', 'title': 'Amazon SDE 2 interview in 3 weeks. What should i focus on?', 'content': 'For system design I found grokking to be the best, for coding it is useful to pay for premium and focus on Amazon questions. As others said LP', 'score': 0.31913248, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1g9pujj/preparing_for_amazon_sde_interview_looking_for/', 'title': 'Preparing for Amazon SDE Interview – Looking for Prep Tips', 'content': 'Commonly asked technical questions (especially around algorithms and data structures). · Example behavioral questions and what to expect', 'score': 0.25902867, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1g942ao/how_to_prepare_for_amazon_sde_interview_new_grad/', 'title': 'How to Prepare for Amazon SDE Interview - New Grad 2024?', 'content': 'What kind of coding questions should I focus on? (Any specific patterns/types?) Generally, the questions are easy/medium, the types vary from', 'score': 0.21905375, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/qz2atz/amazon_final_interview_questions_all_combined/', 'title': 'Amazon Final Interview Questions | All Combined 2021', 'content': 'Fourth round: 2-3 behavioral questions. This was another coding round, which involved taking a string that say said \"This sweater cost $40', 'score': 0.2040566, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/tgxaai/i_have_an_hour_interview_with_live_coding_and_lp/', 'title': 'I have an hour interview with live coding and LP ...', 'content': \"Do Amazon tagged top 30 questions or so sorted based on frequency. Do these questions thoroughly, like understand what's the optimal answer and such.\", 'score': 0.17694198, 'raw_content': None}, {'url': 'https://www.reddit.com/r/leetcode/comments/1h5d3bc/a_detailed_guide_on_how_i_prepared_for_an/', 'title': 'A detailed guide on How I prepared for an interview ...', 'content': 'Onsite interviews typically involve 30–40 minutes of solving problems, dry runs, follow-ups, and managing pressure.', 'score': 0.06261143, 'raw_content': None}], 'response_time': 2.52}), ToolMessage(content='[{\"title\": \"standard Amazon style behavioral interview questions\", \"url\": \"https://www.glassdoor.com/Interview/Behavioral-standard-Amazon-style-behavioral-interview-questions-QTN_6328316.htm\", \"content\": \"Interview question for Staff Software Engineer.Behavioral: standard Amazon style behavioral interview questions.\", \"score\": 0.4921643}, {\"title\": \"Amazon Recruiter Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Recruiter-Interview-Questions-EI_IE6036.0,6_KO7,16.htm\", \"content\": \"Behavioral Interviews: These focus on Amazon\\'s Leadership Principles. You\\'ll be asked to provide specific examples from your past experiences that demonstrate\", \"score\": 0.49128565}, {\"title\": \"Amazon Interview Questions (2025)\", \"url\": \"https://static5.glassdoor.com/Interview/Amazon-Interview-RVW91973762.htm\", \"content\": \"The interview process is not too difficult. They just asked a leetcode easy/medium. The rest of the questions were purely behavioral. Lasts for 45 minutes.\", \"score\": 0.462061}, {\"title\": \"Amazon Risk Manager Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Risk-Manager-Interview-Questions-EI_IE6036.0,6_KO7,19.htm\", \"content\": \"Mainly behavioral questions, answered using STAR format, they want to know that you are process oriented with some technical experience. Most RM roles are\", \"score\": 0.46191534}, {\"title\": \"Amazon Working Student Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Working-Student-Interview-Questions-EI_IE6036.0,6_KO7,22.htm\", \"content\": \"For behavioral questions you need to use the STAR method. Interview questions [1]. Question 1. Tell me about a time when you nearly failed.\", \"score\": 0.43784812}, {\"title\": \"Amazon Interview Question: Behavioral questions\", \"url\": \"https://www.glassdoor.com/Interview/Behavioral-questions-QTN_1988272.htm\", \"content\": \"Would the Sr. Comm Specialist be more demanding in 50-60 hours a week, higher stress, deadlines? It also might be a 10-15% pay reduction. I really like the\", \"score\": 0.4024631}, {\"title\": \"Amazon leadership principles behavioral questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-leadership-principles-behavioral-questions-QTN_6817751.htm\", \"content\": \"Which type of interview question is the biggest waste of time? Behavioral (tell me about a time), Situational (what would you do), Competency (describe your\", \"score\": 0.37676126}, {\"title\": \"Amazon Interview Questions (2025)\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Interview-Questions-E6036.htm\", \"content\": \"Amazon interview details: 63200 interview questions and 58811 interview reviews posted anonymously by Amazon interview candidates.\", \"score\": 0.17034262}, {\"title\": \"Behavioral interview questions aligned with leadership principles.\", \"url\": \"https://www.glassdoor.com/Interview/Behavioral-interview-questions-aligned-with-leadership-principles-QTN_6675001.htm\", \"content\": \"Interview question for Recruitment.Behavioral interview questions aligned with leadership principles..\", \"score\": 0.14813372}, {\"title\": \"Amazon EHS Specialist Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-EHS-Specialist-Interview-Questions-EI_IE6036.0,6_KO7,21.htm\", \"content\": \"26 Amazon EHS Specialist interview questions and 22 interview reviews. Free interview details posted anonymously by Amazon interview candidates.\", \"score\": 0.12561163}]', name='tavily_search_results_json', id='fa07d0c6-c051-4285-b2da-d6df575dbff3', tool_call_id='503fec8d-8a25-4e2b-9a7b-ae1b139d26be', artifact={'query': 'amazon behavioral interview rubric site:glassdoor.com', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.glassdoor.com/Interview/Behavioral-standard-Amazon-style-behavioral-interview-questions-QTN_6328316.htm', 'title': 'standard Amazon style behavioral interview questions', 'content': 'Interview question for Staff Software Engineer.Behavioral: standard Amazon style behavioral interview questions.', 'score': 0.4921643, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Recruiter-Interview-Questions-EI_IE6036.0,6_KO7,16.htm', 'title': 'Amazon Recruiter Interview Questions', 'content': \"Behavioral Interviews: These focus on Amazon's Leadership Principles. You'll be asked to provide specific examples from your past experiences that demonstrate\", 'score': 0.49128565, 'raw_content': None}, {'url': 'https://static5.glassdoor.com/Interview/Amazon-Interview-RVW91973762.htm', 'title': 'Amazon Interview Questions (2025)', 'content': 'The interview process is not too difficult. They just asked a leetcode easy/medium. The rest of the questions were purely behavioral. Lasts for 45 minutes.', 'score': 0.462061, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Risk-Manager-Interview-Questions-EI_IE6036.0,6_KO7,19.htm', 'title': 'Amazon Risk Manager Interview Questions', 'content': 'Mainly behavioral questions, answered using STAR format, they want to know that you are process oriented with some technical experience. Most RM roles are', 'score': 0.46191534, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Working-Student-Interview-Questions-EI_IE6036.0,6_KO7,22.htm', 'title': 'Amazon Working Student Interview Questions', 'content': 'For behavioral questions you need to use the STAR method. Interview questions [1]. Question 1. Tell me about a time when you nearly failed.', 'score': 0.43784812, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Behavioral-questions-QTN_1988272.htm', 'title': 'Amazon Interview Question: Behavioral questions', 'content': 'Would the Sr. Comm Specialist be more demanding in 50-60 hours a week, higher stress, deadlines? It also might be a 10-15% pay reduction. I really like the', 'score': 0.4024631, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-leadership-principles-behavioral-questions-QTN_6817751.htm', 'title': 'Amazon leadership principles behavioral questions', 'content': 'Which type of interview question is the biggest waste of time? Behavioral (tell me about a time), Situational (what would you do), Competency (describe your', 'score': 0.37676126, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Interview-Questions-E6036.htm', 'title': 'Amazon Interview Questions (2025)', 'content': 'Amazon interview details: 63200 interview questions and 58811 interview reviews posted anonymously by Amazon interview candidates.', 'score': 0.17034262, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Behavioral-interview-questions-aligned-with-leadership-principles-QTN_6675001.htm', 'title': 'Behavioral interview questions aligned with leadership principles.', 'content': 'Interview question for Recruitment.Behavioral interview questions aligned with leadership principles..', 'score': 0.14813372, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-EHS-Specialist-Interview-Questions-EI_IE6036.0,6_KO7,21.htm', 'title': 'Amazon EHS Specialist Interview Questions', 'content': '26 Amazon EHS Specialist interview questions and 22 interview reviews. Free interview details posted anonymously by Amazon interview candidates.', 'score': 0.12561163, 'raw_content': None}], 'response_time': 1.85}), ToolMessage(content=[], name='tavily_search_results_json', id='bb7ec9b9-8382-4967-aa32-c206b317302d', tool_call_id='aad8ea0c-07b5-4576-a77f-ab176af56e20', artifact={'query': 'amazon system design interview site:blind.com', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [], 'response_time': 1.6}), ToolMessage(content='[{\"title\": \"Amazon AWS Software Engineer Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-AWS-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,28.htm\", \"content\": \"4 round interview, each round around 30 min BQ and 30 min tech question. Tech question includes 3 coding and 1 system design.\", \"score\": 0.65966886}, {\"title\": \"Amazon Entry Level Software Engineer Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Entry-Level-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,36.htm\", \"content\": \"The first level of the hiring process is a online assessment which includes two questions of hard liquid style questions and a survey.\", \"score\": 0.5726516}, {\"title\": \"Amazon Software Development Engineer In Test Interview ...\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-In-Test-Interview-Questions-EI_IE6036.0,6_KO7,44.htm\", \"content\": \"Interview was phone screen. It was a technical round and interviewer focused on issue identification and investigation. Also asked question on queue and dequeue\", \"score\": 0.57035583}, {\"title\": \"Amazon Software Development Engineer Interview ...\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,36.htm\", \"content\": \"Interview process has 3 steps, online assessment, phone interview with recruiter and interviews with engineers. online assessment was consist of coding test(\", \"score\": 0.5602773}, {\"title\": \"Amazon Software Development Engineer I Interview ...\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-I-Interview-Questions-EI_IE6036.0,6_KO7,38.htm\", \"content\": \"Interview process has 3 steps, online assessment, phone interview with recruiter and interviews with engineers. online assessment was consist of\", \"score\": 0.5573882}, {\"title\": \"Amazon Software Development Engineer II Interview ...\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-II-Interview-Questions-EI_IE6036.0,6_KO7,39.htm\", \"content\": \"I had an OA, followed by an Interview loop of 4 rounds. 3 coding rounds and 1 System design round. Each Round had 2 leadership principles questions followed by\", \"score\": 0.5151571}, {\"title\": \"Amazon Software Development Engineer Intern Interview ...\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-Intern-Interview-Questions-EI_IE6036.0,6_KO7,43.htm\", \"content\": \"45 minute technical and behavioral interview - Amazon-themed leetcode style question, and 2 behavioral questions that they want to see you apply the LPs to.\", \"score\": 0.5069581}, {\"title\": \"Amazon Software Engineer Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,24.htm\", \"content\": \"First, chat with recruiter who will connect you with more recruiters to chat about. A bit of a mess on the recruiting side. First round is a hybrid (typically\", \"score\": 0.48879638}, {\"title\": \"Amazon Front End Engineer Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Front-End-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,25.htm\", \"content\": \"Standard interview process for amazon consisting of behavioral and technical questions. Over 9 hours of interviewing to be ghosted with 0 feedback whatsoever.\", \"score\": 0.46322632}, {\"title\": \"Amazon Communications Specialist Interview Questions\", \"url\": \"https://www.glassdoor.com/Interview/Amazon-Communications-Specialist-Interview-Questions-EI_IE6036.0,6_KO7,32.htm\", \"content\": \"13 Amazon Communications Specialist interview questions and 13 interview reviews. Free interview details posted anonymously by Amazon interview candidates.\", \"score\": 0.3216203}]', name='tavily_search_results_json', id='43dfdcac-0c6e-4d9a-9d53-a1932c84d6f6', tool_call_id='9533b5f4-7bef-4bd9-900c-7038ce9e1453', artifact={'query': 'amazon software engineer interview communication site:glassdoor.com', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.glassdoor.com/Interview/Amazon-AWS-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,28.htm', 'title': 'Amazon AWS Software Engineer Interview Questions', 'content': '4 round interview, each round around 30 min BQ and 30 min tech question. Tech question includes 3 coding and 1 system design.', 'score': 0.65966886, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Entry-Level-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,36.htm', 'title': 'Amazon Entry Level Software Engineer Interview Questions', 'content': 'The first level of the hiring process is a online assessment which includes two questions of hard liquid style questions and a survey.', 'score': 0.5726516, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-In-Test-Interview-Questions-EI_IE6036.0,6_KO7,44.htm', 'title': 'Amazon Software Development Engineer In Test Interview ...', 'content': 'Interview was phone screen. It was a technical round and interviewer focused on issue identification and investigation. Also asked question on queue and dequeue', 'score': 0.57035583, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,36.htm', 'title': 'Amazon Software Development Engineer Interview ...', 'content': 'Interview process has 3 steps, online assessment, phone interview with recruiter and interviews with engineers. online assessment was consist of coding test(', 'score': 0.5602773, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-I-Interview-Questions-EI_IE6036.0,6_KO7,38.htm', 'title': 'Amazon Software Development Engineer I Interview ...', 'content': 'Interview process has 3 steps, online assessment, phone interview with recruiter and interviews with engineers. online assessment was consist of', 'score': 0.5573882, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-II-Interview-Questions-EI_IE6036.0,6_KO7,39.htm', 'title': 'Amazon Software Development Engineer II Interview ...', 'content': 'I had an OA, followed by an Interview loop of 4 rounds. 3 coding rounds and 1 System design round. Each Round had 2 leadership principles questions followed by', 'score': 0.5151571, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-Intern-Interview-Questions-EI_IE6036.0,6_KO7,43.htm', 'title': 'Amazon Software Development Engineer Intern Interview ...', 'content': '45 minute technical and behavioral interview - Amazon-themed leetcode style question, and 2 behavioral questions that they want to see you apply the LPs to.', 'score': 0.5069581, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,24.htm', 'title': 'Amazon Software Engineer Interview Questions', 'content': 'First, chat with recruiter who will connect you with more recruiters to chat about. A bit of a mess on the recruiting side. First round is a hybrid (typically', 'score': 0.48879638, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Front-End-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,25.htm', 'title': 'Amazon Front End Engineer Interview Questions', 'content': 'Standard interview process for amazon consisting of behavioral and technical questions. Over 9 hours of interviewing to be ghosted with 0 feedback whatsoever.', 'score': 0.46322632, 'raw_content': None}, {'url': 'https://www.glassdoor.com/Interview/Amazon-Communications-Specialist-Interview-Questions-EI_IE6036.0,6_KO7,32.htm', 'title': 'Amazon Communications Specialist Interview Questions', 'content': '13 Amazon Communications Specialist interview questions and 13 interview reviews. Free interview details posted anonymously by Amazon interview candidates.', 'score': 0.3216203, 'raw_content': None}], 'response_time': 0.85}), AIMessage(content='```json\\n{\\n  \"company\": \"Amazon\",\\n  \"inferred_rubric\": [\\n    {\\n      \"theme\": \"Leadership Principles\",\\n      \"evidence\": \"Multiple Glassdoor and Reddit snippets mention the importance of answering behavioral questions using Amazon\\'s Leadership Principles.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Recruiter-Interview-Questions-EI_IE6036.0,6_KO7,16.htm\"\\n    },\\n    {\\n      \"theme\": \"Coding Skills\",\\n      \"evidence\": \"Reddit and Glassdoor posts indicate coding rounds with LeetCode easy/medium questions are common.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Interview-RVW91973762.htm\"\\n    },\\n    {\\n      \"theme\": \"System Design\",\\n      \"evidence\": \"Some interview loops include a system design round.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-AWS-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,28.htm\"\\n    },\\n    {\\n      \"theme\": \"Problem Solving\",\\n      \"evidence\": \"Interviewers focus on issue identification and investigation.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-In-Test-Interview-Questions-EI_IE6036.0,6_KO7,44.htm\"\\n    }\\n  ],\\n  \"communication_tips\": [\\n    \"Use the STAR method to answer behavioral questions.\",\\n    \"Prepare examples that demonstrate Amazon\\'s Leadership Principles.\",\\n    \"Practice LeetCode easy/medium questions.\"\\n  ]\\n}\\n```', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, name='knowledge_agent', id='run-38a794e3-7b6f-4ff0-be4f-2f04f34e94f6-0', usage_metadata={'input_tokens': 8032, 'output_tokens': 406, 'total_tokens': 8438, 'input_token_details': {'cache_read': 0}})], 'active_agent': 'knowledge_agent'}\n",
      "content='```json\\n{\\n  \"company\": \"Amazon\",\\n  \"inferred_rubric\": [\\n    {\\n      \"theme\": \"Leadership Principles\",\\n      \"evidence\": \"Multiple Glassdoor and Reddit snippets mention the importance of answering behavioral questions using Amazon\\'s Leadership Principles.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Recruiter-Interview-Questions-EI_IE6036.0,6_KO7,16.htm\"\\n    },\\n    {\\n      \"theme\": \"Coding Skills\",\\n      \"evidence\": \"Reddit and Glassdoor posts indicate coding rounds with LeetCode easy/medium questions are common.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Interview-RVW91973762.htm\"\\n    },\\n    {\\n      \"theme\": \"System Design\",\\n      \"evidence\": \"Some interview loops include a system design round.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-AWS-Software-Engineer-Interview-Questions-EI_IE6036.0,6_KO7,28.htm\"\\n    },\\n    {\\n      \"theme\": \"Problem Solving\",\\n      \"evidence\": \"Interviewers focus on issue identification and investigation.\",\\n      \"discussion_reference\": \"https://www.glassdoor.com/Interview/Amazon-Software-Development-Engineer-In-Test-Interview-Questions-EI_IE6036.0,6_KO7,44.htm\"\\n    }\\n  ],\\n  \"communication_tips\": [\\n    \"Use the STAR method to answer behavioral questions.\",\\n    \"Prepare examples that demonstrate Amazon\\'s Leadership Principles.\",\\n    \"Practice LeetCode easy/medium questions.\"\\n  ]\\n}\\n```' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} name='knowledge_agent' id='run-38a794e3-7b6f-4ff0-be4f-2f04f34e94f6-0' usage_metadata={'input_tokens': 8032, 'output_tokens': 406, 'total_tokens': 8438, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# # --- Agent State ---\n",
    "# class InterviewState(TypedDict):\n",
    "#     messages: List[Any] # Stores the conversation history\n",
    "#     user_resume_path: Optional[str]\n",
    "#     user_jd_path: Optional[str]\n",
    "#     user_resume_text: Optional[str]\n",
    "#     user_jd_text: Optional[str]\n",
    "#     clean_resume: Optional[str]\n",
    "#     clean_jd: Optional[str]\n",
    "#     company_name: Optional[str]\n",
    "#     knowledge_output: Optional[Dict[str, Any]] # Output from Knowledge Agent\n",
    "#     planner_output: Optional[Dict[str, Any]] # Output from Planner Agent (study plan, etc.)\n",
    "#     preferred_question_type: Optional[str]\n",
    "#     generated_question: Optional[str]\n",
    "#     candidate_answer: Optional[str]\n",
    "#     evaluation_output: Optional[Dict[str, Any]] # Output from Evaluation Agent\n",
    "#     current_agent: str # Tracks which agent's turn it is\n",
    "\n",
    "# --- Agent Prompts (from design.md) ---\n",
    "\n",
    "preprocessing_prompt = \"\"\"\n",
    "You are PreprocessingAgent, a specialist in structuring resume and job-description data for downstream analysis.\n",
    "You will be given paths to the user's resume and the job description. Parse these files and extract the text.\n",
    "Generate embeddings for both the resume and job description, saving them to the specified FAISS paths.\n",
    "For all other tasks, handover to the next agent after performing your functions.\n",
    "\n",
    "1. Call `extract_text_with_ocr` for both the resume file (`user_resume_path`) and the job description file (`user_jd_path`).\n",
    "2. Clean the extracted text: Remove headers, footers, duplicate whitespace, and decorative lines. Store these as `clean_resume` and `clean_jd`.\n",
    "   *(Self-correction: Labeling sections like [CONTACT...] is complex and better handled by downstream agents if needed. Focus on cleaning and embedding.)*\n",
    "3. Extract the 'COMPANY NAME' from the cleaned job description (`clean_jd`).\n",
    "4. Call `generate_embeddings_and_save` **once for `clean_resume`**, saving to ../faiss/resume_embeddings.\n",
    "5. Call `generate_embeddings_and_save` **once for `clean_jd`**, saving to ../faiss/jd_embeddings .\n",
    "6. Hand over the extracted Company Name and Job Title to the knowledge agent for retrieving company-specific knowledge from the web.\n",
    "\"\"\"\n",
    "\n",
    "knowledge_prompt = \"\"\"\n",
    "You are the Knowledge Agent in a multi-agent interview preparation system. Your role is to ONLY extract real-world, subjective expectations about how top companies evaluate technical candidates during interviews using the job description as a reference. \n",
    "You must infer the evaluation rubric, communication expectations, common patterns, and failure modes using a web search tool. You must also generate the knowledge embeddings using the results from your web search.  \n",
    "For all other tasks, handover to the next agent after performing your functions.\n",
    "\n",
    "## Tools Available:\n",
    "\n",
    "### 1. Tavily Tool\n",
    "- Performs web search queries across Reddit, Glassdoor, Blind, Medium, and other platforms.\n",
    "- Returns concise snippets and links, not full articles.\n",
    "- Snippets often contain behavioral signals or reflections from interviewees.\n",
    "\n",
    "### 2. retrieve_jd_embeddings_from_vector_db\n",
    "- Retrieve details relevant to the Job Description from the JD FAISS index.\n",
    "\n",
    "### 3. generate_knowledge_embeddings_and_save tool\n",
    "- Use to the results of your web search to create embeddings\n",
    "- Save them to a FAISS index at `\"./faiss/knowledge_embeddings\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs:\n",
    "- The company and the job title to analyze (e.g., \"Uber\").\n",
    "\n",
    "---\n",
    "\n",
    "## Search Strategy:\n",
    "Construct at least 4 queries using variations like:\n",
    "- coding interview expectations site:reddit.com\n",
    "- behavioral interview rubric site:glassdoor.com\n",
    "- system design interview site:blind.com\n",
    "\n",
    "---\n",
    "\n",
    "## Goals:\n",
    "1. Use the Tavily Tool to collect search result snippets about the company’s interview process.\n",
    "2. For each snippet, analyze and infer themes such as:\n",
    "   - Ownership\n",
    "   - Tradeoff Thinking\n",
    "   - Structured Reasoning\n",
    "   - Handling Ambiguity\n",
    "   - Communication Style\n",
    "3. Cluster the themes and summarize them as a list of `inferred_rubric` items.\n",
    "4. From the language and tone of the snippets, extract 3–5 actionable `communication_tips`.\n",
    "5. Pass the snippet list and associated metadata into `generate_embeddings` to persist them in FAISS.\n",
    "6. Hand over the output to the planner agent for generating the study plan, and all other tasks\n",
    "\n",
    "---\n",
    "\n",
    "## Output Format:\n",
    "Return a JSON object in the format:\n",
    "```json\n",
    "{\n",
    "  \"company\": \"XYZ\",\n",
    "  \"inferred_rubric\": [\n",
    "    {\n",
    "      \"theme\": \"Ownership\",\n",
    "      \"evidence\": \"Multiple Reddit users reported being asked how they would proactively handle fallback strategies.\",\n",
    "      \"discussion_reference\": \"https://www.reddit.com/r/csMajors/comments/abc123\"\n",
    "    },\n",
    "    {\n",
    "      \"theme\": \"Tradeoff Thinking\",\n",
    "      \"evidence\": \"Glassdoor snippets emphasize discussing time-space tradeoffs during implementation decisions.\",\n",
    "      \"discussion_reference\": \"https://www.glassdoor.com/Interview/XYZ-Interview-Questions.htm\"\n",
    "    }\n",
    "  ],\n",
    "  \"communication_tips\": [\n",
    "    \"Narrate your approach clearly before coding.\",\n",
    "    \"Always explain tradeoffs when discussing solutions.\",\n",
    "    \"Discuss scalability and edge case assumptions upfront.\"\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "planner_prompt = \"\"\"\n",
    "You are the Planner Agent, orchestrating interview preparation. You are only responsible for generating a study plan, curating a list of relevant leetcode problems and inferring the company-specific evaluation rubric. \n",
    "For all other tasks, handover to the next agent after performing your functions.\n",
    "\n",
    "\n",
    "**Inputs You Have Access To (implicitly via state or tools)**:\n",
    "- Parsed Resume Context (from ../faiss/resume_embeddings )\n",
    "- Parsed Job Description Context (from ../faiss/jd_embeddings )\n",
    "- Knowledge Agent Output: `inferred_rubric` and `communication_tips` for the company.\n",
    "- User Preference: `preferred_question_type` (e.g., 'technical', 'behavioral').\n",
    "\n",
    "**Your Responsibilities**:\n",
    "1.  **Synthesize**: Briefly analyze the alignment between resume, JD, and company insights.\n",
    "2.  **Generate Study Plan**: Create a concise, actionable study plan (markdown format).\n",
    "3.  **Suggest LeetCode**: Call `company_leetcode_retriever` for the company.\n",
    "4.  **Present Insights**: Format and include the `inferred_rubric` and `communication_tips` in your output.\n",
    "5.  **Embed Insights**: Call `generate_embeddings_and_save` to save the combined text of the rubric and tips to the rubric path\n",
    "6.  **Prepare for Question Agent**: Note the `preferred_question_type` for the next step.\n",
    "7. Hand over the output to the question agent\n",
    "\n",
    "**Output Format**:\n",
    "Return **only** a JSON object like this:\n",
    "```json\n",
    "{\n",
    "  \"study_plan\": \"<Markdown formatted study plan>\",\n",
    "  \"suggested_leetcode\": [\"<LeetCode Q1>\", \"<LeetCode Q2>\"],\n",
    "  \"company_insights_display\": {\n",
    "    \"company\": \"...\",\n",
    "    \"inferred_rubric\": [ ... ],\n",
    "    \"communication_tips\": [ ... ]\n",
    "  },\n",
    "  \"embedding_status\": \"<Status message from generate_embeddings_and_save>\",\n",
    "  \"next_action\": \"Proceed to generate a question.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "question_prompt = \"\"\"\n",
    "You are the Question Agent. Your goal is to generate a single, relevant, open-ended interview question.\n",
    "\n",
    "For all other tasks, handover to the next agent after performing your functions.\n",
    "\n",
    "**Inputs You Have Access To (implicitly via state or tools)**:\n",
    "- Question Type Requested:\n",
    "- Company: \n",
    "- Contextual Data (via `retrieve_from_vector_db` from ../faiss/resume_embeddings, ./faiss/jd_embeddings)\n",
    "\n",
    "**Your Task**:\n",
    "1. Call `retrieve_from_vector_db` using relevant queries (e.g., job title, key skills, company name, question type) against the resume, JD, and rubric indices to gather context.\n",
    "2. Synthesize the retrieved context.\n",
    "3. Generate **one** interview question of the type that is:\n",
    "    - Tailored to the company.\n",
    "    - Relevant to the job description and candidate's likely experience.\n",
    "    - Aligned with the company's inferred rubric/culture (if available).\n",
    "    - Clear, professional, and open-ended.\n",
    "4. Output the question to the user in a JSON format. This signals completion.\n",
    "\n",
    "**Output Format**:\n",
    "Return **only** a JSON object like this:\n",
    "```json\n",
    "{\n",
    "  \"question\": \"<The generated interview question>\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = \"\"\"\n",
    "You are EvaluationFeedbackAgent, a senior interview coach.\n",
    "\n",
    "\n",
    "For all other tasks, handover to the next agent after performing your functions.\n",
    "\n",
    "\n",
    "**Given**:\n",
    "- question:\n",
    "- candidate_answer: \n",
    "- company_tag: \n",
    "- rubric_index_path: \n",
    "\n",
    "**Do the following**:\n",
    "1. Call `retrieve_rubric_snippets` using the `question` and `company_tag` to get relevant evaluation criteria.\n",
    "2. Call `generate_ideal_answer` for the `question` and `company_tag`.\n",
    "3. Call `rewrite_candidate_answer` for the `question` and `candidate_answer`.\n",
    "4. Call `critique_and_advise` using all inputs.\n",
    "   - The critique must highlight strengths, list missed elements (e.g., complexity, STAR method), suggest improvements, use bullet points, and bold key terms.\n",
    "\n",
    "**Output Format**:\n",
    "Return **only** this JSON:\n",
    "```json\n",
    "{\n",
    "  \"ideal_answer\": \"<Output from generate_ideal_answer>\",\n",
    "  \"improved_answer\": \"<Output from rewrite_candidate_answer>\",\n",
    "  \"detailed_feedback\": \"<Output from critique_and_advise>\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# # Create nodes\n",
    "# preprocess_tools = [extract_text_with_ocr, generate_resume_embeddings_and_save, generate_jd_embeddings_and_save]\n",
    "# preprocess_agent_node = create_agent_node(preprocessing_prompt, preprocess_tools)\n",
    "\n",
    "# knowledge_tools = [tavily_tool, generate_resume_embeddings_and_save, generate_jd_embeddings_and_save]\n",
    "# knowledge_agent_node = create_agent_node(knowledge_prompt, knowledge_tools)\n",
    "\n",
    "# planner_tools = [company_leetcode_problem_retriever, generate_resume_embeddings_and_save, generate_jd_embeddings_and_save, generate_rubric_embeddings_and_save]\n",
    "# planner_agent_node = create_agent_node(planner_prompt, planner_tools)\n",
    "\n",
    "# question_tools = [retrieve_jd_embeddings_from_vector_db,retrieve_rubric_embeddings_from_vector_db]\n",
    "# question_agent_node = create_agent_node(question_prompt, question_tools)\n",
    "\n",
    "# evaluation_tools = [retrieve_resume_embeddings_from_vector_db,retrieve_jd_embeddings_from_vector_db,retrieve_rubric_embeddings_from_vector_db,retrieve_rubric_snippets, generate_ideal_answer, rewrite_candidate_answer, critique_and_advise]\n",
    "# evaluation_agent_node = create_agent_node(evaluation_prompt, evaluation_tools)\n",
    "\n",
    "def record_audio(duration=5, fs=16000):\n",
    "  print(\"🎙️ Speak now...\")\n",
    "  audio_file = f\"/tmp/test_audio_{uuid.uuid4()}.wav\"\n",
    "\n",
    "  recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "  sd.wait()\n",
    "  recording = np.int16(recording * 32767)\n",
    "  wav.write(audio_file, fs, recording)\n",
    "  print(\"✅ Audio recorded and saved.\")\n",
    "  return audio_file\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "  client = speech.SpeechClient()\n",
    "\n",
    "  with open(file_path, \"rb\") as audio_file:\n",
    "      content = audio_file.read()\n",
    "\n",
    "  audio = speech.RecognitionAudio(content=content)\n",
    "  config = speech.RecognitionConfig(\n",
    "      encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "      sample_rate_hertz=16000,\n",
    "      audio_channel_count=1,\n",
    "      language_code=\"en-US\",\n",
    "      enable_automatic_punctuation=True\n",
    "  )\n",
    "\n",
    "  response = client.recognize(config=config, audio=audio)\n",
    "  if not response.results:\n",
    "      return \"[No speech detected]\"\n",
    "\n",
    "  transcript = \" \".join(result.alternatives[0].transcript for result in response.results)\n",
    "  return transcript.strip()\n",
    "\n",
    "# Custom record agent that records audio and transcribes it\n",
    "async def record_agent(state, config):\n",
    "  \"\"\"\n",
    "    Records audio from the user and transcribes it into text using Google Cloud Speech-to-Text.\n",
    "    The transcript is saved to `candidate_answer` in the state.\n",
    "  \"\"\"\n",
    "  print(\"🎧 Running record agent...\")\n",
    "  audio_path = record_audio()\n",
    "  transcript = transcribe_audio(audio_path)\n",
    "  os.remove(audio_path)\n",
    "  state[\"candidate_answer\"] = transcript\n",
    "  return {\"messages\": []}\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "record_agent_node = ToolNode([record_agent], name=\"record_agent\")\n",
    "\n",
    "# Creating Agent Nodes\n",
    "preprocess_tools = [extract_text_with_ocr, generate_resume_embeddings_and_save, generate_jd_embeddings_and_save, create_handoff_tool(agent_name='knowledge_agent', description=\"Hand over to Knowledge Agent for web search, rubric inference and generating knowledge embeddings\")]\n",
    "preprocess_agent_node = create_react_agent(\n",
    "    gemini_model,\n",
    "    preprocess_tools,\n",
    "    prompt=preprocessing_prompt,\n",
    "    name='preprocess_agent'\n",
    ")\n",
    "\n",
    "knowledge_tools = [tavily_tool, retrieve_jd_embeddings_from_vector_db, generate_knowledge_embeddings_and_save, create_handoff_tool(agent_name='planner_agent')]\n",
    "knowledge_agent_node = create_react_agent(\n",
    "    gemini_model,\n",
    "    knowledge_tools,\n",
    "    prompt=knowledge_prompt,\n",
    "    name='knowledge_agent'\n",
    ")\n",
    "\n",
    "planner_tools = [company_leetcode_problem_retriever, retrieve_resume_embeddings_from_vector_db, retrieve_jd_embeddings_from_vector_db, retrieve_knowledge_embeddings_from_vector_db, generate_rubric_embeddings_and_save, create_handoff_tool(agent_name='question_agent')]\n",
    "planner_agent_node = create_react_agent(\n",
    "    gemini_model,\n",
    "    planner_tools,\n",
    "    prompt=planner_prompt,\n",
    "    name='planner_agent'\n",
    ")\n",
    "\n",
    "question_tools = [retrieve_resume_embeddings_from_vector_db, retrieve_jd_embeddings_from_vector_db, retrieve_knowledge_embeddings_from_vector_db, create_handoff_tool(agent_name='record_agent', description=\"Hand over to Record Agent to capture user answer.\")]\n",
    "question_agent_node = create_react_agent(\n",
    "    gemini_model,\n",
    "    question_tools,\n",
    "    prompt=question_prompt,\n",
    "    name='question_agent'\n",
    ")\n",
    "\n",
    "evaluation_tools = [retrieve_resume_embeddings_from_vector_db, retrieve_jd_embeddings_from_vector_db, retrieve_rubric_embeddings_from_vector_db, generate_ideal_answer, rewrite_candidate_answer, critique_and_advise]\n",
    "evaluation_agent_node = create_react_agent(\n",
    "    gemini_model,\n",
    "    evaluation_tools,\n",
    "    prompt=evaluation_prompt,\n",
    "    name='evaluation_agent'\n",
    ")\n",
    "\n",
    "\n",
    "workflow = create_swarm(\n",
    "    agents=[\n",
    "        preprocess_agent_node,\n",
    "        knowledge_agent_node,\n",
    "        planner_agent_node,\n",
    "        question_agent_node,\n",
    "        record_agent_node\n",
    "    ],\n",
    "    default_active_agent='preprocess_agent'\n",
    ")\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": 1}}\n",
    "\n",
    "turn_1 = graph.invoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"The file path to my resume and jd is ./Mandar_Burande_Resume.pdf and ./amazon-jd.txt. Give me a study plan for cracking an interview with this company and also a list of popular leetcode problems for this company. Based on my experience, skills and projects from my resume, suggest me a question that will help me improve my skills for this company.\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(turn_1)\n",
    "print(turn_1['messages'][-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983228b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea73c5fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a761bab",
   "metadata": {},
   "source": [
    "## 4. Graph Definition\n",
    "\n",
    "Define the workflow connecting the agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cba1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Graph Construction ---\n",
    "# workflow = StateGraph(InterviewState)\n",
    "\n",
    "# # # Add nodes for each agent and their tools\n",
    "# workflow.add_node(\"preprocess\", preprocess_agent_node)\n",
    "# # workflow.add_node(\"preprocess_tools\", preprocess_tool_node)\n",
    "# workflow.add_node(\"knowledge\", knowledge_agent_node)\n",
    "# # workflow.add_node(\"knowledge_tools\", knowledge_tool_node)\n",
    "# workflow.add_node(\"planner\", planner_agent_node)\n",
    "# # workflow.add_node(\"planner_tools\", planner_tool_node)\n",
    "# workflow.add_node(\"question\", question_agent_node)\n",
    "# # workflow.add_node(\"question_tools\", question_tool_node)\n",
    "# workflow.add_node(\"record_answer\", record_and_transcribe_audio) # Direct tool call node\n",
    "# workflow.add_node(\"evaluate\", evaluation_agent_node)\n",
    "# # workflow.add_node(\"evaluate_tools\", evaluation_tool_node)\n",
    "\n",
    "# # Define edges\n",
    "# workflow.set_entry_point(\"preprocess\")\n",
    "\n",
    "# # Preprocessing Agent Logic\n",
    "# # workflow.add_edge(\"preprocess\", \"preprocess_tools\")\n",
    "# # workflow.add_conditional_edges(\n",
    "# #     \"preprocess_tools\",\n",
    "# #     tools_condition,\n",
    "# #     {\"continue\": \"knowledge\", END: END} # If tool call needed, loop back via tools_condition, else go to knowledge\n",
    "# # )\n",
    "# workflow.add_edge(\"preprocess\", \"knowledge\")\n",
    "# workflow.add_edge(\"knowledge\", \"planner\")\n",
    "# workflow.add_edge(\"planner\", \"question\")\n",
    "# workflow.add_edge(\"question\", \"record_answer\")\n",
    "# workflow.add_edge(\"record_answer\", \"evaluate\")\n",
    "\n",
    "# # Knowledge Agent Logic\n",
    "# # workflow.add_edge(\"knowledge\", \"knowledge_tools\")\n",
    "# # workflow.add_conditional_edges(\n",
    "# #     \"knowledge_tools\",\n",
    "# #     tools_condition,\n",
    "# #     {\"continue\": \"planner\", END: END}\n",
    "# # )\n",
    "\n",
    "# # # Planner Agent Logic\n",
    "# # workflow.add_edge(\"planner\", \"planner_tools\")\n",
    "# # workflow.add_conditional_edges(\n",
    "# #     \"planner_tools\",\n",
    "# #     tools_condition,\n",
    "# #     {\"continue\": \"question\", END: END}\n",
    "# # )\n",
    "\n",
    "# # # Question Agent Logic\n",
    "# # workflow.add_edge(\"question\", \"question_tools\")\n",
    "# # workflow.add_conditional_edges(\n",
    "# #     \"question_tools\",\n",
    "# #     tools_condition,\n",
    "# #     {\"continue\": \"record_answer\", END: END} # After question is generated, record answer\n",
    "# # )\n",
    "\n",
    "# # # Record Answer Node\n",
    "# # workflow.add_edge(\"record_answer\", \"evaluate\") # After recording, go to evaluation\n",
    "\n",
    "# # # Evaluation Agent Logic\n",
    "# # workflow.add_edge(\"evaluate\", \"evaluate_tools\")\n",
    "# # workflow.add_conditional_edges(\n",
    "# #     \"evaluate_tools\",\n",
    "# #     tools_condition,\n",
    "# #     {\"continue\": END, END: END} # End after evaluation\n",
    "# # )\n",
    "\n",
    "# # Compile the graph\n",
    "# # graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# # print(\"Graph compiled successfully!\")\n",
    "# # # Optional: Visualize the graph\n",
    "# # try:\n",
    "# #     from IPython.display import Image, display\n",
    "# #     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# # except Exception as e:\n",
    "# #     print(f\"Could not display graph: {e}. Make sure graphviz and mermaid are installed/configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9011b1",
   "metadata": {},
   "source": [
    "## 5. Execution and Interaction\n",
    "\n",
    "Run the graph with user inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b111476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import pprint\n",
    "\n",
    "# # --- Execution ---\n",
    "\n",
    "# # IMPORTANT: Set the path to your Google Cloud credentials file\n",
    "# # This is needed for the record_and_transcribe_audio tool\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"key.json\" # Replace with the actual path to your key.json\n",
    "\n",
    "# # --- User Inputs ---\n",
    "# # !!! IMPORTANT: Replace these with the actual paths to your files !!!\n",
    "# resume_file = os.path.join(os.getcwd(), \"Mandar Burande_Resume.pdf\") # e.g., \"/path/to/your/resume.pdf\"\n",
    "# jd_file = os.path.join(os.getcwd(), \"amazon-jd.txt\") #\"/path/to/your/job_description.txt\"\n",
    "# user_preferred_question_type = \"technical\" # Options: \"technical\", \"behavioral\", \"system design\", \"debugging/problem-solving\"\n",
    "\n",
    "# # Create dummy files if they don't exist for the example run\n",
    "# if not os.path.exists(resume_file):\n",
    "#     with open(resume_file, \"w\") as f:\n",
    "#         f.write(\"Sample Resume Content: Python Developer with 5 years experience in web development and data analysis.\")\n",
    "# if not os.path.exists(jd_file):\n",
    "#      with open(jd_file, \"w\") as f:\n",
    "#         f.write(\"Sample Job Description: Looking for a Senior Software Engineer at Google. Requires strong Python skills, experience with distributed systems, and cloud platforms.\")\n",
    "\n",
    "# # Define the initial state to start the graph\n",
    "# initial_state = {\n",
    "#     \"messages\": [],\n",
    "#     \"user_resume_path\": resume_file,\n",
    "#     \"user_jd_path\": jd_file,\n",
    "#     \"preferred_question_type\": user_preferred_question_type,\n",
    "#     \"current_agent\": \"preprocess\" # Start with the preprocessing agent\n",
    "# }\n",
    "\n",
    "# # Configuration for the graph run (e.g., unique thread ID)\n",
    "# config = {\"configurable\": {\"thread_id\": \"interview-prep-thread-1\"}}\n",
    "\n",
    "# async def run_graph():\n",
    "#     final_state = None\n",
    "#     print(\"--- Starting Interview Prep Workflow ---\")\n",
    "#     print(f\"Resume: {resume_file}\")\n",
    "#     print(f\"Job Description: {jd_file}\")\n",
    "#     print(f\"Preferred Question Type: {user_preferred_question_type}\")\n",
    "#     print(\"-\" * 30)\n",
    "\n",
    "#     async for event in graph.astream_events(initial_state, config, version=\"v1\"):\n",
    "#         kind = event[\"event\"]\n",
    "#         tags = event.get(\"tags\", [])\n",
    "#         if kind == \"on_chat_model_stream\":\n",
    "#             content = event[\"data\"][\"chunk\"].content\n",
    "#             if content:\n",
    "#                 # Print LLM tokens as they arrive\n",
    "#                 print(content, end=\"|\")\n",
    "#         elif kind == \"on_tool_start\":\n",
    "#             print(f\"\\n--- Calling Tool: {event['name']} ---\")\n",
    "#             print(f\"   Args: {event['data'].get('input')}\")\n",
    "#         elif kind == \"on_tool_end\":\n",
    "#             print(f\"--- Tool Result: {event['name']} ---\")\n",
    "#             print(f\"   Output: {event['data'].get('output')}\")\n",
    "#             print(\"-\" * 30)\n",
    "#         elif kind == \"on_chain_end\":\n",
    "#              # Check if it's the end of a specific agent node run\n",
    "#             if event[\"name\"] in [\"preprocess\", \"knowledge\", \"planner\", \"question\", \"evaluate\"]:\n",
    "#                  print(f\"\\n--- Finished Agent: {event['name']} ---\")\n",
    "#                  # pprint.pprint(event['data'].get('output'), indent=2) # Print agent output if needed\n",
    "#                  print(\"-\" * 30)\n",
    "\n",
    "\n",
    "#         # Track the final state\n",
    "#         if kind == \"on_graph_end\":\n",
    "#             final_state = event['data']['output']\n",
    "\n",
    "\n",
    "#     print(\"\\n--- Workflow Complete ---\")\n",
    "\n",
    "#     if final_state:\n",
    "#         print(\"\\n--- Final Results ---\")\n",
    "#         # Extract and print key information from the final state\n",
    "#         planner_output = final_state.get('planner_output', {})\n",
    "#         evaluation_output = final_state.get('evaluation_output', {})\n",
    "\n",
    "#         print(\"\\n**Study Plan:**\")\n",
    "#         print(planner_output.get('study_plan', 'Not generated.'))\n",
    "\n",
    "#         print(\"\\n**Suggested LeetCode:**\")\n",
    "#         pprint.pprint(planner_output.get('suggested_leetcode', 'Not generated.'))\n",
    "\n",
    "#         print(\"\\n**Company Insights:**\")\n",
    "#         pprint.pprint(planner_output.get('company_insights_display', 'Not generated.'))\n",
    "\n",
    "#         print(f\"\\n**Generated Question ({final_state.get('preferred_question_type', 'N/A')}):**\")\n",
    "#         print(final_state.get('generated_question', 'Not generated.'))\n",
    "\n",
    "#         print(\"\\n**Your Transcribed Answer:**\")\n",
    "#         # The actual transcribed answer isn't directly stored in the state by the tool node,\n",
    "#         # but it was passed to the evaluation agent. We print the placeholder for clarity.\n",
    "#         # In a real UI, you'd capture the output of the 'record_answer' node.\n",
    "#         print(final_state.get('candidate_answer', '[Answer was recorded and passed to evaluation]'))\n",
    "\n",
    "\n",
    "#         print(\"\\n**Evaluation Feedback:**\")\n",
    "#         print(\"\\n*Ideal Answer (Placeholder):*\")\n",
    "#         print(evaluation_output.get('ideal_answer', 'Not generated.'))\n",
    "#         print(\"\\n*Improved Answer (Placeholder):*\")\n",
    "#         print(evaluation_output.get('improved_answer', 'Not generated.'))\n",
    "#         print(\"\\n*Detailed Feedback (Placeholder):*\")\n",
    "#         print(evaluation_output.get('detailed_feedback', 'Not generated.'))\n",
    "#     else:\n",
    "#         print(\"Workflow did not complete successfully or final state not captured.\")\n",
    "\n",
    "# # Run the asynchronous function\n",
    "# import traceback\n",
    "\n",
    "# try:\n",
    "#     await run_graph()\n",
    "# except Exception as e:\n",
    "#     print(\"\\nAn error occurred during graph execution:\")\n",
    "#     traceback.print_exc()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
